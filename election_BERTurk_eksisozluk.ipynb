{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data From Eksisozluk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used https://github.com/coluck/eksisozluk-api for scraping the data from\n",
    "Eksisozluk. It's based on node.js, and it returns data in a json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entries_to_text(entry_dataframe: pd.DataFrame) -> str:\n",
    "    \"\"\"A function to merge all of the entries in a page given by the Eksisozluk\n",
    "    API. Also handles the removal of HTML tags found in the raw results from\n",
    "    the API.\"\"\"\n",
    "    final_text = ''\n",
    "    for entry in entry_dataframe['body']:\n",
    "        soup = BeautifulSoup(entry)\n",
    "        final_text = ' '.join([final_text, soup.get_text()])\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_pages_to_str(start_page: int, end_page: int, header_link: str) -> str:\n",
    "    \"\"\"A function that uses Eksisozluk API to process all of the entries in the \n",
    "    given page range to a string.\"\"\"\n",
    "    text_out = ''\n",
    "    for i in range(start_page, end_page):\n",
    "        req = requests.get(f\"{header_link}?p={i}\")\n",
    "        entries = pd.DataFrame.from_dict(req.json()[\"entries\"])\n",
    "        text_out = ' '.join([text_out, entries_to_text(entries)])\n",
    "    return text_out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_pages_to_df(start_page: int, end_page: int, header_link: str) -> pd.DataFrame:\n",
    "    \"\"\"A function that uses Eksisozluk API to process all of the entries in the \n",
    "    given page range to a Pandas Data Frame. Also handles the removal of HTML\n",
    "    tags found in the raw results from the API.\"\"\"\n",
    "    df_out = pd.DataFrame()\n",
    "    soup = BeautifulSoup()\n",
    "    for i in range(start_page, end_page):\n",
    "        req = requests.get(f\"{header_link}?p={i}\")\n",
    "        entries = pd.DataFrame(req.json()[\"entries\"])\n",
    "        df_out = pd.concat([entries, df_out])\n",
    "    df_out = df_out.reset_index(drop=True)\n",
    "    df_out[\"cleaned_body\"] = [BeautifulSoup(entry).get_text() for entry in df_out[\"body\"]]\n",
    "    return df_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting some entries about the main opposition candidate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t3/37z1vnv119jd4057sptnmv900000gn/T/ipykernel_9860/452042521.py:12: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df_out[\"cleaned_body\"] = [BeautifulSoup(entry).get_text() for entry in df_out[\"body\"]]\n"
     ]
    }
   ],
   "source": [
    "#Page 4247 corresponds to entries written on May 1\n",
    "# Page 4404 ends the night before the election day\n",
    "kilicdar_text = scan_pages_to_df(4247, 4404, 'http://localhost:3000/api/baslik/kemal-kilicdaroglu--1267550')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned BERTurk Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", tokenizer=sent_tokenizer, model=sent_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out entries that produce more than 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 20562, 7362, 2623, 5124, 7065, 16, 2345, 2965, 27870, 1031, 3236, 1992, 18392, 16516, 2637, 2811, 31461, 5179, 6664, 5693, 5621, 18, 6, 6271, 16, 2684, 18756, 2107, 23210, 1987, 3596, 2061, 2287, 14845, 5558, 2023, 29907, 16847, 2984, 1022, 4602, 5244, 2016, 18, 2536, 2051, 24403, 6682, 1029, 1976, 2337, 2042, 22409, 8175, 1975, 2678, 1992, 6975, 6975, 22552, 16531, 2011, 4602, 5244, 2110, 2339, 19950, 2020, 29985, 5224, 2085, 7600, 2061, 18, 57, 10855, 22780, 3117, 3439, 2631, 26746, 22565, 16, 4783, 4394, 1013, 16, 9456, 16282, 4258, 2684, 2866, 4670, 9929, 5304, 5027, 18, 6, 8731, 25895, 6629, 2637, 70, 4420, 18328, 2468, 10463, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenizer(kilicdar_text[\"cleaned_body\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilicdar_clean = kilicdar_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3088 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(kilicdar_clean[\"cleaned_body\"])):\n",
    "    if len(sent_tokenizer(kilicdar_clean[\"cleaned_body\"][i])[\"input_ids\"]) > 512:\n",
    "        kilicdar_clean.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.7617455124855042},\n",
       " {'label': 'positive', 'score': 0.9610978364944458}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(list(kilicdar_clean[\"cleaned_body\"])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>sentiment_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152322598</td>\n",
       "      <td>açıkçası sadece tatlı dili, uzlaşmacı yanı ve ...</td>\n",
       "      <td>okhako</td>\n",
       "      <td>2245868</td>\n",
       "      <td>2</td>\n",
       "      <td>13.05.2023 22:55</td>\n",
       "      <td>13.05.2023 22:56</td>\n",
       "      <td>açıkçası sadece tatlı dili, uzlaşmacı yanı ve ...</td>\n",
       "      <td>{'label': 'positive', 'score': 0.7617455124855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152322891</td>\n",
       "      <td>bu akşam anadolunun şirin bir ilçesinde&lt;sup cl...</td>\n",
       "      <td>karate kamil</td>\n",
       "      <td>566889</td>\n",
       "      <td>0</td>\n",
       "      <td>13.05.2023 23:00</td>\n",
       "      <td>14.05.2023 00:18</td>\n",
       "      <td>bu akşam anadolunun şirin bir ilçesinde* hamam...</td>\n",
       "      <td>{'label': 'positive', 'score': 0.9610978364944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152323083</td>\n",
       "      <td>bu akşam kurmaylarına şu sözü söylediğine emin...</td>\n",
       "      <td>konsensus1</td>\n",
       "      <td>2057317</td>\n",
       "      <td>0</td>\n",
       "      <td>13.05.2023 23:03</td>\n",
       "      <td>13.05.2023 23:10</td>\n",
       "      <td>bu akşam kurmaylarına şu sözü söylediğine emin...</td>\n",
       "      <td>{'label': 'positive', 'score': 0.5693134069442...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152323096</td>\n",
       "      <td>yarın 13. cumhurbaşkanı olacak</td>\n",
       "      <td>ekcord</td>\n",
       "      <td>2189546</td>\n",
       "      <td>2</td>\n",
       "      <td>13.05.2023 23:03</td>\n",
       "      <td>None</td>\n",
       "      <td>yarın 13. cumhurbaşkanı olacak</td>\n",
       "      <td>{'label': 'positive', 'score': 0.9607189893722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152323206</td>\n",
       "      <td>seçimi kazanması halinde mafyatik rakipleri il...</td>\n",
       "      <td>gaditano</td>\n",
       "      <td>1460908</td>\n",
       "      <td>0</td>\n",
       "      <td>13.05.2023 23:05</td>\n",
       "      <td>None</td>\n",
       "      <td>seçimi kazanması halinde mafyatik rakipleri il...</td>\n",
       "      <td>{'label': 'negative', 'score': 0.6322678327560...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               body        author  \\\n",
       "0  152322598  açıkçası sadece tatlı dili, uzlaşmacı yanı ve ...        okhako   \n",
       "1  152322891  bu akşam anadolunun şirin bir ilçesinde<sup cl...  karate kamil   \n",
       "2  152323083  bu akşam kurmaylarına şu sözü söylediğine emin...    konsensus1   \n",
       "3  152323096                     yarın 13. cumhurbaşkanı olacak        ekcord   \n",
       "4  152323206  seçimi kazanması halinde mafyatik rakipleri il...      gaditano   \n",
       "\n",
       "  author_id fav_count        created_at        updated_at  \\\n",
       "0   2245868         2  13.05.2023 22:55  13.05.2023 22:56   \n",
       "1    566889         0  13.05.2023 23:00  14.05.2023 00:18   \n",
       "2   2057317         0  13.05.2023 23:03  13.05.2023 23:10   \n",
       "3   2189546         2  13.05.2023 23:03              None   \n",
       "4   1460908         0  13.05.2023 23:05              None   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  açıkçası sadece tatlı dili, uzlaşmacı yanı ve ...   \n",
       "1  bu akşam anadolunun şirin bir ilçesinde* hamam...   \n",
       "2  bu akşam kurmaylarına şu sözü söylediğine emin...   \n",
       "3                     yarın 13. cumhurbaşkanı olacak   \n",
       "4  seçimi kazanması halinde mafyatik rakipleri il...   \n",
       "\n",
       "                                      sentiment_data  \n",
       "0  {'label': 'positive', 'score': 0.7617455124855...  \n",
       "1  {'label': 'positive', 'score': 0.9610978364944...  \n",
       "2  {'label': 'positive', 'score': 0.5693134069442...  \n",
       "3  {'label': 'positive', 'score': 0.9607189893722...  \n",
       "4  {'label': 'negative', 'score': 0.6322678327560...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilicdar_clean_sentiments_small = kilicdar_clean.iloc[:5].copy()\n",
    "kilicdar_clean_sentiments_small[\"sentiment_data\"] = [sentiment_pipeline(list(kilicdar_clean_sentiments_small[\"cleaned_body\"])[i])[0] for i in range(len(kilicdar_clean_sentiments_small))]\n",
    "kilicdar_clean_sentiments_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'positive', 'score': 0.7617455124855042}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilicdar_clean_sentiments_small[\"sentiment_data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilicdar_clean_sentiments = kilicdar_clean.copy()\n",
    "kilicdar_clean_sentiments[\"sentiment_data\"] = [sentiment_pipeline(list(kilicdar_clean_sentiments[\"cleaned_body\"])[i])[0] for i in range(len(kilicdar_clean_sentiments))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kilicdar_clean_sentiments = kilicdar_clean_sentiments.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_sentiment(df: pd.DataFrame) -> int:\n",
    "    sentiment = 0\n",
    "    for i in range(len(df)):\n",
    "        sentiment += df[\"sentiment_data\"][i][\"score\"] if df[\"sentiment_data\"][i][\"label\"] == \"positive\" else -df[\"sentiment_data\"][i][\"score\"]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-52.535507559776306"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_sentiment(kilicdar_clean_sentiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turkey-election",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
